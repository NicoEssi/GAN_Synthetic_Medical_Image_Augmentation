{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFcKTXScmbLrWmGc2WDiqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoEssi/GAN_Synthetic_Medical_Image_Augmentation/blob/master/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDPiz6r2lCo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dependencies\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "# Data Imports\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqvxYEn9lFTN",
        "colab_type": "text"
      },
      "source": [
        "# Project Description\n",
        "Generative adversarial networks, or GANs, are a class of machine learning systems that are used to generate new data given a data set, with the same statistical properties. Our work aims to display the effectiveness of new data generation as a form of image augmentation technique to improve the predictive performance of a convolutional neural network. Our work will be demonstrated with and without the synthetic image augmentation, for comparative purposes.\n",
        "\n",
        "![alt text](https://i.imgur.com/7ouwAEA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhyGvlXjlauJ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Exploration\n",
        "\n",
        "First we start by inspecting the data, as it may be potentially fruitful to us to try to gain an intuition for what kind of visual features we might find particularly useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM-ypRZolXBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYAdydPQldEk",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Preparation\n",
        "\n",
        "Now we prepare our data. We create small batches of 200 images, belonging to three classes. Each class with different distributions (between 50 to 100 images in each class). Due to this distributional bias, we will present our findings with sensitivity and specificity metrics.\n",
        "\n",
        "![\"recall\"](https://i.imgur.com/1tWumNb.png)\n",
        "\n",
        "We will also look into using classic augmentations to enhance our dataset, including: rotations, flips, translations, and scaling. And note down how our metrics improve using these.\n",
        "\n",
        "Later on, we will create more data through synthetic means - by utilizing our own built and trained DCGAN, to see whether or not our model improves and by how much if it does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZGUBfPxlcXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHVpum_7qNe0",
        "colab_type": "text"
      },
      "source": [
        "# 3. CNN Construction\n",
        "We will implement a fairly simple convolutional neural network, as it is our intention to show that the data will overfit the model and then to show how the synthetic data augmentation will help us improve our model. Below is a visualization of how our network is constructed.\n",
        "\n",
        "![Our CNN](https://i.imgur.com/30fh1DJ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_OKMiG8qXeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLEASE VERIFY THAT THE MODEL IS BUILT CORRECTLY\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(256, activation = 'relu'))\n",
        "model.add(layers.Dense(3, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4PjOqgrzZ7",
        "colab_type": "text"
      },
      "source": [
        "#4. Training and Results\n",
        "\n",
        "Now we train our simple CNN with our prepared data, and note down our results for both the non-augmented and augmented dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJPiAhc8qaAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g79YZ4Eu3Po",
        "colab_type": "text"
      },
      "source": [
        "#5. DCGAN Construction\n",
        "\n",
        "While the paper itself also implemented the AC-GAN; it is significantly more complex to implement in comparison to the DCGAN - which is the most straightforward model to understand. DCGAN improves upon the original GAN design by incorporating upsampling convolutional layers, amongst other details such as Batch Normalization and Leaky ReLU activations with the slope set to 0.2.\n",
        "\n",
        "The paper also found that they had significantly better results using the synthetic data from the DCGAN than the AC-GAN. For these reasons, we exclusively build the DCGAN for this particular project.\n",
        "\n",
        "Important to note that the input to the DCGAN model consists only of individual classes, thus the generated output will only consist of one class. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wATfoau7nKl",
        "colab_type": "text"
      },
      "source": [
        "## 5.1. Generator Construction\n",
        "\n",
        "![alt text](https://i.imgur.com/01krVDp.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN_bz1EV7m4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that 'None' in the \"assert\" is our batch size ;)\n",
        "def dcgenerator_model():\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtxuwucH7phS",
        "colab_type": "text"
      },
      "source": [
        "## 5.2. Discriminator Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLeqI6Ztu2uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCsIMV8PAHYn",
        "colab_type": "text"
      },
      "source": [
        "## 5.3. Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99knxsqzALsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function for our generator\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Loss function for our discriminator\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPAQt5EXAZKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqLGISfZAtmW",
        "colab_type": "text"
      },
      "source": [
        "## 5.4. Defining Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSJAiz4AvT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSWsF2t4Ax1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChviLcHrA0_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Might be a good idea to add function that generates an image during training\n",
        "  # time to time."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFZv6vlAgZe",
        "colab_type": "text"
      },
      "source": [
        "## 5.4. Checkpointing\n",
        "\n",
        "Will be very helpful in case our model starts training for a long time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzGnf7QgAdMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVo1xUrcwbzK",
        "colab_type": "text"
      },
      "source": [
        "#6. Training the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbqR2rKwsO99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5WiNGhGBFHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNurxRIxg9M",
        "colab_type": "text"
      },
      "source": [
        "# 7. Synthetic Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY5gs4MuxgkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJueNDJU3Nfz",
        "colab_type": "text"
      },
      "source": [
        "# 8. Training CNN with Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDurcIZF3Sl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZuHjxAJ4q1O",
        "colab_type": "text"
      },
      "source": [
        "# 9. Separability Visualization (optional)\n",
        "\n",
        "An interesting optional step is to visualize how the synthetic data strenghtens the separability between the three classes, with some dimensionality reduction method such as t-SNE (which is what the authors used). Should look something like the image below, where left is without synthetic data and right is with the synthetic data. Need to emphasize though: this is optional :)\n",
        "\n",
        "![separability](https://www.henryailabs.com/ArticlePictures/MedicalImageAugmentation-8.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km_JB8sm5PHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}